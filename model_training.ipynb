{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce1d02a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a2a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "File paths\n",
    "'''\n",
    "import os\n",
    "\n",
    "folder = os.path.join(\"/projectnb\",\"cs542sp\",\"netflix_wrw2\", \"CS542-final-project\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e478a6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_04.bin',\n",
       " 'data_05.bin',\n",
       " 'data_03.bin',\n",
       " 'full_data.bin',\n",
       " 'data_09.bin',\n",
       " 'data_02.bin',\n",
       " 'data_06.bin',\n",
       " 'data_07.bin',\n",
       " 'Baseline Info.docx',\n",
       " 'data_01.bin',\n",
       " 'data_08.bin',\n",
       " 'data_00.bin',\n",
       " 'who_rated_what_2006.sas7bdat',\n",
       " 'netflix_analysis_dataset.sas7bdat',\n",
       " 'who_rated_what_2006_ans_use.sas7bdat']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(os.walk(folder))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e153e75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 µs, sys: 0 ns, total: 17 µs\n",
      "Wall time: 18.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# read the lightgbm data for chunk 1\n",
    "train = lgbm.Dataset(os.path.join(folder, 'data_03.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d5d322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the validation set\n",
    "valid = lgbm.Dataset(os.path.join(folder, 'data_02.bin'), reference=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24e5ed59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Load from binary file /projectnb/cs542sp/netflix_wrw2/CS542-final-project/data/data_03.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x2b7fa210c0a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.construct()\n",
    "valid.construct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef3ee60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.num_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e7d3dae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Load from binary file /projectnb/cs542sp/netflix_wrw2/CS542-final-project/data/data_03.bin\n",
      "[LightGBM] [Info] Number of positive: 8242599, number of negative: 11757154\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.862736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2154\n",
      "[LightGBM] [Info] Number of data points in the train set: 19999753, number of used features: 12\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Cannot add validation data, since it has different bin mappers with training data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_valid_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_valid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_valid_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_valid_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reverse_update_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36madd_valid\u001b[0;34m(self, data, name)\u001b[0m\n\u001b[1;32m   2555\u001b[0m             raise LightGBMError(\"Add validation data failed, \"\n\u001b[1;32m   2556\u001b[0m                                 \"you should use same predictor for these data\")\n\u001b[0;32m-> 2557\u001b[0;31m         _safe_call(_LIB.LGBM_BoosterAddValidData(\n\u001b[0m\u001b[1;32m   2558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m             data.construct().handle))\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Cannot add validation data, since it has different bin mappers with training data"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# build the model\n",
    "\n",
    "'''\n",
    "https://sites.google.com/view/lauraepp/parameters\n",
    "\n",
    "learning_rate: < 0.05\n",
    "early_stopping_round: 10% num rounds\n",
    "max_depth: [3 12] ~ larger better but overfitting speed increase\n",
    "max_leaves: 2^max_depth-1 \n",
    "'''\n",
    "\n",
    "params = {}\n",
    "# binary classification\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary_logloss'\n",
    "\n",
    "# model constants (don't change these!)\n",
    "params['learning_rate'] = 0.005\n",
    "params['boosting_type'] = 'gbdt'\n",
    "\n",
    "# tree size\n",
    "params['max_depth'] = 7\n",
    "params['num_leaves'] = 127\n",
    "\n",
    "# speed up training rate with bagging\n",
    "params['bagging_freq'] = 5\n",
    "params['bagging_fraction'] = 0.5\n",
    "\n",
    "num_rounds = 100\n",
    "\n",
    "# early stopping rounds requires validation set!\n",
    "\n",
    "bst = lgbm.train(params, data, num_rounds, valid_sets = [valid], early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "bst.save_model(os.path.join('models', 'model.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d51b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
